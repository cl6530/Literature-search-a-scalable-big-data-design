{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "855a0e4a-a7cb-4b7a-a8f7-ae8ee1a613e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin\n",
    "\n",
    "'''\n",
    "This is a function to get all the links that contains the content of the txt books.\n",
    "The max depth of link within link is 2, to retrieve all links, we check all link start with 'http://www.authorama.com/'\n",
    "'''\n",
    "def get_all_links(url, depth=0, max_depth=1):\n",
    "    if depth > max_depth:\n",
    "        return []\n",
    "\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    links = []\n",
    "    for link in soup.find_all('a'):\n",
    "        href = link.get('href')\n",
    "        absolute_url = urljoin(url, href)\n",
    "        if absolute_url.startswith('http://www.authorama.com/'):\n",
    "            links.append(absolute_url)\n",
    "            nested_links = get_all_links(absolute_url, depth=depth+1, max_depth=max_depth)\n",
    "            links.extend(nested_links)\n",
    "\n",
    "    return links\n",
    "\n",
    "url = 'http://www.authorama.com/'\n",
    "book_links = get_all_links(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f5c7c9d-7966-4ba6-93dd-0169e7360f2f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import re\n",
    "\n",
    "def extract_chapter_number(url):\n",
    "    base_name = os.path.basename(url)\n",
    "    chapter_number = base_name.split('-')[-1].split('.')[0]\n",
    "    return chapter_number\n",
    "\n",
    "def get_book_details(book_url):\n",
    "    response = requests.get(book_url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    \n",
    "    title_author = soup.title\n",
    "    if title_author:\n",
    "        title_author = title_author.string\n",
    "        match = re.search(r'(.*)\\s\\(by\\s(.*)\\)', title_author)\n",
    "        \n",
    "        if match:\n",
    "            title = match.group(1).strip()\n",
    "            author = match.group(2).strip()\n",
    "        else:\n",
    "            title = title_author\n",
    "            author = \"Unknown\"\n",
    "    else:\n",
    "        title = \"Unknown\"\n",
    "        author = \"Unknown\"\n",
    "\n",
    "    chapter = extract_chapter_number(book_url)\n",
    "\n",
    "    content = []\n",
    "\n",
    "    for paragraph in soup.find_all('p'):\n",
    "        content.append(paragraph.text)\n",
    "\n",
    "    book_details = {\n",
    "        'title': title,\n",
    "        'author': author,\n",
    "        'chapter': chapter,\n",
    "        'content': content\n",
    "    }\n",
    "\n",
    "    return book_details\n",
    "\n",
    "def save_book_as_json(book_details, output_dir):\n",
    "    filename = os.path.join(output_dir, book_details['title'].replace(' ', '_') + '_chapter_' + book_details['chapter'] + '.json')\n",
    "\n",
    "    with open(filename, 'w', encoding='utf-8') as file:\n",
    "        json.dump(book_details, file, ensure_ascii=False, indent=4)\n",
    "\n",
    "output_dir = '/Users/chenxiliu/Documents/bd23spchenxi/bdfinalproject/crawl_text'\n",
    "for book_link in book_links:\n",
    "    book_details = get_book_details(book_link)\n",
    "    save_book_as_json(book_details, output_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c1066f1-9342-417d-9356-13503e870e25",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
